from urllib import request
import rarfile
import requests
import os
from bs4 import BeautifulSoup
import ssl
import mysql.connector
import simpledbf
import os
import dataset
import datetime
from zipfile import ZipFile
from contextlib import closing
import csv
from dbfread import DBF
from multiprocessing import Process
import sys
import dbf

try:
    import pymysql
    pymysql.install_as_MySQLdb()
except ImportError:
    pass
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
# Legacy Python that doesn't verify HTTPS certificates by default
    pass
else:
# Handle target environment that doesn't support HTTPS verification
    ssl._create_default_https_context = _create_unverified_https_context


def dbf_to_csv(dbf_table_pth):  # Input a dbf, output a csv, same name, same path, except extension
    csv_fn = dbf_table_pth[:-4] + ".csv"  # Set the csv file name
    table = dbf.Table(dbf_table_pth, codepage='cp866')  # table variable is a DBF object
    with open(csv_fn, 'w', newline='', encoding='cp866') as f:  # create a csv file, fill it with dbf content
        writer = csv.writer(f, delimiter=',')
        table.open(mode=dbf.READ_WRITE)
        writer.writerow(table.field_names)  # write the column name
        print(table.field_names)
        if(len(table.field_names)==6):
            for record in table:  # write the rows
                a = []
                try:
                    a.append(record.regn)
                    a.append(record.code)
                    a.append(record.sim_r)
                    a.append(record.sim_v)
                    a.append(record.sim_itogo)
                    a.append(record.dt)
                    writer.writerow(a)
                except dbf.FieldMissingError:
                    break
        if(len(table.field_names)==2):
            for record in table:  # write the rows
                a = []
                try:
                    a.append(record.regn)
                    a.append(record.name_b)
                    writer.writerow(a)
                except dbf.FieldMissingError:
                    break
        elif(len(table.field_names)==3):
            for record in table:  # write the rows
                a = []
                try:
                    a.append(record.cont_sum_r)
                    a.append(record.cont_sum_v)
                    a.append(record.cont_sum)
                    writer.writerow(a)
                except dbf.FieldMissingError:
                    break


    return csv_fn  # return the csv name


def Get_New_dbf(url):

    mydb = mysql.connector.connect(
                                    auth_plugin='mysql_native_password',
                                    user="root",
                                    password="1234",
                                    database="all_in_one",
                                   )
    mycursor = mydb.cursor(buffered=True)

    query = "select * from all_dt"
    mycursor.execute(query)
    datafetch = mycursor.fetchall()
    print(len(datafetch))
    print(datafetch[len(datafetch)-1])
    t = datafetch[len(datafetch)-1][1]
    dt = t.strftime('%Y%m%d')
    print(dt)
    print(url[22:30])
    if (url[22:30] != dt):
        url_date = url[22:26] + '-' + url[26:28] + '-' + url[28:30]
        print(url_date)
        next_id = len(datafetch) + 1
        next_id = str(next_id)
        sql = "INSERT INTO all_dt (id, Date) VALUES (" + next_id + ",'" + url_date + "')"
        print(sql)
        mycursor.execute(sql)
        mydb.commit()
        print(url)
        '''Открываю сайт, качаю в Rar.rar файлы'''
        r = requests.get(r'https://www.cbr.ru' + url, allow_redirects=True)
        open('RAR.rar', 'wb')
        with open('RAR.rar', 'wb') as f:
            f.write(r.content)

        # Retrieve HTTP meta-data
        print(r.status_code)
        print(r.headers['content-type'])
        print(r.encoding)
        #

        name = 'C:/Users/Ivant/PycharmProjects/Dima/RAR.rar'

        rf = rarfile.RarFile(name)
        for k in range(3):
            print(rf.namelist())
            LastPath = rf.namelist()[k]
            print(LastPath)
            file_path = 'C:/RAR_STUFF/' + LastPath
            if not os.path.exists(file_path):
                rf.extractall('C:/RAR_STUFF')
            filen = LastPath[:-4]
            filet = LastPath[5:-4]
            # file_csv = filen + '.csv'
            path = 'C:/RAR_STUFF/' + LastPath
            file_csv = dbf_to_csv(path)
            file_test = 'C:/RAR_STUFF/12020_P11.csv'
            # for arg in sys.argv[1:]:
            #     dbf.export(arg)
            # print(filet)

            MAINQUERRY = {'auth_plugin': 'mysql_native_password',
                          'user': "root",
                          'password': "1234",
                          'database': "all_in_one",
                          'allow_local_infile': "True"}
            cnx = mysql.connector.connect(**MAINQUERRY)
            curs = cnx.cursor(buffered=True)
            q0 = "CREATE TABLE IF NOT EXISTS " + filen + " like 42019" + filet + ";"
            print(q0)
            q1 = "LOAD DATA LOCAL INFILE '"+file_csv+"' INTO TABLE " + filen
            print(q1)
            q2 = " CHARACTER SET cp866"
            q3 = " FIELDS TERMINATED BY ','"
            q4 = " ENCLOSED BY '\"'"
            q5 = " LINES TERMINATED BY '\\r\\n'"
            q6 = " IGNORE 1 LINES;"
            querload = q1 + q2 + q3 + q4 + q5 + q6
            quercommit = 'commit;'
            # curs.execute(q0)
            curs.execute(querload)
            curs.execute(quercommit)
            curs.close()


def Download_Start():
    ########        '''constants'''
    cbr = []      #cbr[0] = ""
    i=0
    #######

    '''Получение ссылок'''
    quote_page = 'https://www.cbr.ru/banking_sector/otchetnost-kreditnykh-organizaciy/'
    page = request.urlopen(quote_page)
    soup = BeautifulSoup(page, 'html.parser')
    for link in soup.find_all('a'):
        if '.rar' in link.get('href') and '102-' in link.get('href'):
            cbr.append(link.get('href'))
            i+=1
            break

    '''Connectим mysql'''
    mydb = mysql.connector.connect(
                auth_plugin='mysql_native_password',
                user="root",
                password="1234",
    )
    '''Создаём бд'''
    mycursor = mydb.cursor()
    all_dbfs = "Every"
    database = "CREATE DATABASE IF NOT EXISTS " + all_dbfs
    print(database)
    mycursor.execute(database)

    '''Обрабатываю ссылки в скачивание в бд и таблицы'''
    print(cbr)
    Get_New_dbf(cbr[0])

Download_Start()
